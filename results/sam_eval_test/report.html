<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SAM-Evals Benchmark Report</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@sgratzl/chartjs-chart-boxplot"></script>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1600px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }
        
        .header {
            background: linear-gradient(135deg, #27ae60 0%, #2ecc71 100%);
            color: white;
            padding: 1rem;
            border-radius: 8px;
            margin-bottom: 1.5rem;
            text-align: center;
        }
        
        .header h1 {
            margin: 0;
            font-size: 1.8rem;
            font-weight: 400;
        }
        
        .section {
            background: white;
            padding: 1.5rem;
            border-radius: 8px;
            margin-bottom: 1.5rem;
            box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        }
        
        .section h2 {
            color: #2c3e50;
            border-bottom: 3px solid #27ae60;
            padding-bottom: 0.5rem;
            margin-top: 0;
            font-size: 1.4rem;
        }
        
        .info-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 0.2rem;
            margin-bottom: 1rem;
        }
        
        .info-item {
            background: #f8f9fa;
            padding: 0.8rem;
            border-radius: 5px;
            border-left: 4px solid #27ae60;
        }
        
        .info-item strong {
            color: #2c3e50;
            display: block;
            margin-bottom: 0.3rem;
            font-size: 0.9rem;
        }
        
        .chart-container {
            position: relative;
            height: 400px;
            margin: 1.5rem 0;
        }
        
        .model-list {
            display: flex;
            flex-wrap: wrap;
            gap: 0.4rem;
            margin-top: 0.4rem;
        }
        
        .model-tag {
            background: #27ae60;
            color: white;
            padding: 0.2rem 0.6rem;
            border-radius: 12px;
            font-size: 0.85rem;
        }
        
        .test-files {
            background: #f8f9fa;
            padding: 0.8rem;
            border-radius: 5px;
            margin-top: 0.8rem;
        }
        
        .test-files ul {
            margin: 0.4rem 0 0 0;
            padding-left: 1.2rem;
        }
        
        .test-files li {
            font-size: 0.9rem;
        }
        
        .evaluation-status {
            display: inline-block;
            padding: 0.2rem 0.6rem;
            border-radius: 12px;
            font-size: 0.85rem;
            font-weight: bold;
        }
        
        .enabled {
            background: #d4edda;
            color: #155724;
        }
        
        .disabled {
            background: #f8d7da;
            color: #721c24;
        }
        
        .breakdown-container {
            margin-top: 1rem;
        }
        
        .category-section {
            margin-bottom: 1.5rem;
            border: 1px solid #e9ecef;
            border-radius: 8px;
            overflow: hidden;
        }
        
        .category-header {
            background: #f8f9fa;
            padding: 1rem;
            cursor: pointer;
            border-bottom: 1px solid #e9ecef;
            display: flex;
            justify-content: space-between;
            align-items: center;
            transition: background-color 0.2s;
        }
        
        .category-header:hover {
            background: #e9ecef;
        }
        
        .category-title {
            font-size: 1.1rem;
            font-weight: 600;
            color: #2c3e50;
            margin: 0;
        }
        
        .category-toggle {
            font-size: 1.2rem;
            color: #2c3e50;
            transition: transform 0.2s;
        }
        
        .category-content {
            display: none;
            padding: 0.8rem;
        }
        
        .category-content.active {
            display: block;
        }
        
        .test-item {
            background: #f8f9fa;
            padding: 0.4rem 0.6rem;
            margin-bottom: 0.3rem;
            border-radius: 4px;
            border-left: 3px solid #6c757d;
            font-size: 0.85rem;
        }
        
        .test-header {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            margin-bottom: 0.2rem;
        }
        
        .test-name {
            font-weight: 600;
            color: #2c3e50;
            font-size: 0.95rem;
        }
        
        .test-description {
            font-size: 0.8rem;
            color: #6c757d;
            font-style: italic;
        }
        
        .model-scores {
            display: flex;
            gap: 0.6rem;
            flex-wrap: wrap;
            margin-top: 0.3rem;
        }
        
        .model-score {
            padding: 0.25rem 0.5rem;
            border-radius: 3px;
            font-size: 0.8rem;
            color: white;
            font-weight: 600;
        }
        
        .score-high {
            background: #27ae60; /* Green background for scores >= 0.7 */
        }
        
        .score-medium {
            background: #f39c12; /* Yellow/Orange background for scores 0.4-0.69 */
        }
        
        .score-low {
            background: #e74c3c; /* Red background for scores < 0.4 */
        }
        
        /* Detailed breakdown styles */
        .model-result {
            padding: 0.6rem;
            margin-bottom: 0;
            border-radius: 6px;
            border: 1px solid #e9ecef;
            box-shadow: 0 1px 3px rgba(0,0,0,0.05);
            display: flex;
            align-items: center;
            gap: 0.8rem;
            flex-wrap: wrap;
        }
        
        .model-result.score-high {
            background: #27ae60;
            border-color: #1e8449;
        }
        
        .model-result.score-medium {
            background: #f39c12;
            border-color: #d68910;
        }
        
        .model-result.score-low {
            background: #e74c3c;
            border-color: #c0392b;
        }
        
        .model-result .model-score {
            display: inline-block;
            padding: 0.25rem 0.5rem;
            border-radius: 4px;
            font-size: 0.85rem;
            color: white;
            font-weight: 600;
            margin-bottom: 0;
            background: rgba(0,0,0,0.2);
        }
        
        .model-result .score-value {
            background: rgba(255,255,255,0.9);
            padding: 0.2rem 0.5rem;
            border-radius: 3px;
            font-weight: 600;
            border: 1px solid rgba(255,255,255,0.3);
            font-size: 0.8rem;
            color: #2c3e50;
        }
        
        .model-result .avg-duration {
            background: rgba(255,255,255,0.9);
            padding: 0.2rem 0.5rem;
            border-radius: 3px;
            font-weight: 600;
            border: 1px solid rgba(255,255,255,0.3);
            font-size: 0.8rem;
            color: #2c3e50;
        }
        
        .score-value {
            color: #2c3e50 !important;
            font-weight: 600 !important;
        }
        
        .success-rate {
            color: #27ae60 !important;
        }
        
        .avg-duration {
            color: #2c3e50 !important;
            font-weight: 600 !important;
        }
        
        .run-count {
            color: #6c757d !important;
            font-style: italic;
        }
        
        .model-results {
            margin-top: 0.5rem;
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 0.8rem;
        }
        
        @media (max-width: 768px) {
            .info-grid {
                grid-template-columns: 1fr;
            }
            
            .header h1 {
                font-size: 1.5rem;
            }
            
            .model-scores {
                flex-direction: column;
                gap: 0.3rem;
            }
            
            .test-header {
                flex-direction: column;
                align-items: flex-start;
                gap: 0.2rem;
            }
        }
    

/* Modal Styles */
/* Modal Styles */
.modal {
    display: none;
    position: fixed;
    z-index: 1000;
    left: 0;
    top: 0;
    width: 100%;
    height: 100%;
    background-color: rgba(0,0,0,0.5);
}

.modal-content {
    background-color: white;
    margin: 2% auto;
    padding: 2rem;
    border-radius: 8px;
    width: 90%;
    max-width: 1200px;
    max-height: 90vh;
    overflow-y: auto;
    position: relative;
}

.modal-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 1rem;
    border-bottom: 2px solid #e9ecef;
    padding-bottom: 1rem;
}

.modal-title {
    font-size: 1.5rem;
    font-weight: 600;
    color: #2c3e50;
    margin: 0;
}

.modal-description {
    font-size: 1rem;
    color: #6c757d;
    font-style: italic;
    margin-bottom: 1.5rem;
    padding: 0.5rem 0;
}

.modal-close {
    background: none;
    border: none;
    font-size: 2rem;
    color: #6c757d;
    cursor: pointer;
    padding: 0;
    width: 2rem;
    height: 2rem;
    display: flex;
    align-items: center;
    justify-content: center;
}

.modal-close:hover {
    color: #2c3e50;
}

.modal-charts {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 2rem;
    margin-top: 1rem;
}

.modal-chart-container {
    background: #f8f9fa;
    padding: 1rem;
    border-radius: 8px;
    border: 1px solid #e9ecef;
}

.modal-chart-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 1rem;
}

.modal-chart-title {
    font-size: 1.1rem;
    font-weight: 600;
    color: #2c3e50;
}

.chart-toggle-btn {
    background: #27ae60;
    color: white;
    border: none;
    padding: 0.5rem 1rem;
    border-radius: 4px;
    font-size: 0.875rem;
    cursor: pointer;
    transition: background-color 0.2s;
}

.chart-toggle-btn:hover {
    background: #219a52;
}

.chart-flip-container {
    position: relative;
    height: 300px;
    perspective: 1000px;
}

.chart-face {
    position: absolute;
    width: 100%;
    height: 100%;
    backface-visibility: hidden;
    transition: transform 0.6s;
}

.chart-front {
    transform: rotateY(0deg);
}

.chart-back {
    transform: rotateY(180deg);
}

.chart-flip-container.flipped .chart-front {
    transform: rotateY(-180deg);
}

.chart-flip-container.flipped .chart-back {
    transform: rotateY(0deg);
}

.test-item {
    cursor: pointer !important;
    transition: background-color 0.2s;
}

.test-item:hover {
    background: #e9ecef !important;
}

/* Make test names clickable but not hyperlinked */
.test-name {
    cursor: pointer !important;
}

.test-name:hover {
    color: #2c3e50 !important;
    font-weight: 700 !important;
}

.modal-runs-section {
    margin-top: 2rem;
    border-top: 2px solid #e9ecef;
    padding-top: 1.5rem;
}

.runs-section-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 1.5rem;
    flex-wrap: wrap;
    gap: 1rem;
}

.runs-section-title {
    font-size: 1.3rem;
    font-weight: 600;
    color: #2c3e50;
    margin: 0;
}

.runs-controls {
    display: flex;
    align-items: center;
    gap: 1.5rem;
    flex-wrap: wrap;
}

.runs-filter {
    display: flex;
    align-items: center;
    gap: 0.5rem;
}

.runs-filter label {
    font-size: 0.9rem;
    font-weight: 500;
    color: #495057;
}

.runs-filter select {
    padding: 0.375rem 0.75rem;
    border: 1px solid #ced4da;
    border-radius: 4px;
    font-size: 0.875rem;
    background-color: white;
    color: #495057;
    cursor: pointer;
}

.runs-filter select:focus {
    outline: none;
    border-color: #007bff;
    box-shadow: 0 0 0 0.2rem rgba(0, 123, 255, 0.25);
}

.runs-count {
    font-size: 0.875rem;
    color: #6c757d;
    font-style: italic;
}

.runs-container {
    display: grid;
    gap: 1rem;
}

.run-item {
    background: #f8f9fa;
    border: 1px solid #e9ecef;
    border-radius: 8px;
    padding: 1rem;
}

.run-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 0.75rem;
    padding-bottom: 0.5rem;
    border-bottom: 1px solid #e9ecef;
}

.run-model {
    font-size: 1rem;
    font-weight: 600;
    color: #2c3e50;
}

.run-scores {
    display: flex;
    gap: 0.75rem;
}

.run-score {
    padding: 0.25rem 0.5rem;
    border-radius: 4px;
    font-size: 0.875rem;
    font-weight: 600;
    color: white;
}

.run-score.response {
    background: #007bff;
}

.run-score.tool {
    background: #6f42c1;
}

.run-score.llm {
    background: #28a745;
}

.run-reasoning {
    margin-top: 0.75rem;
}

.reasoning-label {
    font-size: 0.9rem;
    font-weight: 600;
    color: #495057;
    margin-bottom: 0.5rem;
}

.reasoning-text {
    font-size: 0.875rem;
    color: #6c757d;
    line-height: 1.5;
    background: white;
    padding: 0.75rem;
    border-radius: 4px;
    border: 1px solid #e9ecef;
}

@media (max-width: 768px) {
    .modal-content {
        margin: 5% auto;
        width: 95%;
        padding: 1rem;
    }
    
    .modal-charts {
        grid-template-columns: 1fr;
        gap: 1rem;
    }
    
    .chart-flip-container {
        height: 250px;
    }
    
    .modal-chart-header {
        flex-direction: column;
        gap: 0.5rem;
        align-items: stretch;
    }
    
    .chart-toggle-btn {
        width: 100%;
    }
    
    .runs-section-header {
        flex-direction: column;
        align-items: flex-start;
    }
    
    .runs-controls {
        width: 100%;
        justify-content: space-between;
    }
    
    .run-header {
        flex-direction: column;
        align-items: flex-start;
        gap: 0.5rem;
    }
    
    .run-scores {
        flex-wrap: wrap;
        gap: 0.5rem;
    }
}

</style>
</head>
<body>
    <div class="header">
        <h1>SAM-Evals Benchmark Report</h1>
    </div>
<div class="section">
    <h2>📊 Benchmark Run Information</h2>
    <div class="info-grid">
        <div class="info-item">
            <strong>Time of Execution</strong>
            August 01, 2025 at 10:56 AM
        </div>
        <div class="info-item">
            <strong>Number of Runs</strong>
            1 run per test case
        </div>
        <div class="info-item">
            <strong>Total Test Cases</strong>
            6
        </div>
        <div class="info-item">
            <strong>Evaluation Duration</strong>
            12 minutes 1 seconds
        </div>
    </div>

    <div class="info-item">
        <strong>Tested Models (2)</strong>
        <div class="model-list">
            <span class="model-tag">claude-3-7-sonnet</span><span class="model-tag">gemini-2.5-flash</span>
        </div>
    </div>

    <div class="test-files">
        <strong>Test Cases Executed:</strong>
        <ul>
            <li>convert_pdf_to_markdown.test.json</li><li>generate_complex_report.test.json</li><li>generate_image.test.json</li><li>generate_mermaid_diagram.test.json</li><li>simple_hello_world.test.json</li><li>web_search_summary.test.json</li>
        </ul>
    </div>
</div>
<div class="section">
    <h2>📈 Performance Results</h2>
    <div class="chart-container" style="position: relative; height: 500px; margin: 20px 0;">
        <canvas id="performanceChart"></canvas>
    </div>
    
    <!-- Model Execution Times -->
    <div class="execution-times-section" style="margin-top: 30px;">
        <h3 style="color: #1f2937; margin-bottom: 15px; font-size: 1.2rem;">Model Execution Times</h3>
        <div class="execution-times-grid" style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 15px;">
            
                    <div style="background: #f9fafb; padding: 15px; border-radius: 8px; border-left: 4px solid #6b7280; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
                        <div style="font-weight: 600; color: #1f2937; margin-bottom: 5px; font-size: 1rem;">claude-3-7-sonnet</div>
                        <div style="color: #6b7280; font-weight: 700; font-size: 1.25rem; font-family: 'SF Mono', Monaco, 'Cascadia Code', 'Roboto Mono', Consolas, 'Courier New', monospace;">8m 57s</div>
                        <div style="color: #6b7280; font-size: 0.85rem; margin-top: 2px;">Total execution time</div>
                    </div>
                
                    <div style="background: #f9fafb; padding: 15px; border-radius: 8px; border-left: 4px solid #6b7280; box-shadow: 0 1px 3px rgba(0,0,0,0.1);">
                        <div style="font-weight: 600; color: #1f2937; margin-bottom: 5px; font-size: 1rem;">gemini-2.5-flash</div>
                        <div style="color: #6b7280; font-weight: 700; font-size: 1.25rem; font-family: 'SF Mono', Monaco, 'Cascadia Code', 'Roboto Mono', Consolas, 'Courier New', monospace;">2m 28s</div>
                        <div style="color: #6b7280; font-size: 0.85rem; margin-top: 2px;">Total execution time</div>
                    </div>
                
        </div>
    </div>
    
</div>

<!-- Chart.js Library -->
<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>

<!-- Chart Data and Configuration -->
<script>
// Chart data from backend
const CATEGORIES_DATA = ["Agent Delegation", "Artifacts", "Basic Functionality"];
const CHART_DATASETS_DATA = [{"label": "claude-3-7-sonnet", "data": [1.0, 0.467, 1.0], "backgroundColor": "#9edc45", "borderColor": "#9edc45", "borderWidth": 1, "borderRadius": 4, "borderSkipped": false}, {"label": "gemini-2.5-flash", "data": [1.0, 0.667, 0.4], "backgroundColor": "#a855f7", "borderColor": "#a855f7", "borderWidth": 1, "borderRadius": 4, "borderSkipped": false}];

// Chart.js configuration for benchmark report - Grouped Bar Chart
const ctx = document.getElementById('performanceChart').getContext('2d');
const chart = new Chart(ctx, {
    type: 'bar',
    data: {
        labels: CATEGORIES_DATA,
        datasets: CHART_DATASETS_DATA
    },
    options: {
        responsive: true,
        maintainAspectRatio: false,
        interaction: {
            mode: 'index',
            intersect: false,
        },
        plugins: {
            title: {
                display: true,
                text: 'LLM Evaluation Scores by Category',
                font: {
                    size: 20,
                    weight: 'bold'
                },
                color: '#000000',
                padding: {
                    top: 10,
                    bottom: 30
                }
            },
            legend: {
                display: true,
                position: 'top',
                labels: {
                    color: '#000000',
                    padding: 20,
                    usePointStyle: true,
                    font: {
                        size: 12
                    }
                }
            },
            tooltip: {
                backgroundColor: 'rgba(0, 0, 0, 0.8)',
                titleColor: '#ffffff',
                bodyColor: '#ffffff',
                borderColor: '#ffffff',
                borderWidth: 1,
                callbacks: {
                    label: function(context) {
                        const score = context.parsed.y;
                        const percentage = (score * 100).toFixed(1);
                        return `${context.dataset.label}: ${score.toFixed(3)} (${percentage}%)`;
                    }
                }
            }
        },
        scales: {
            y: {
                beginAtZero: true,
                max: 1.0,
                title: {
                    display: true,
                    text: 'Average LLM Evaluation Score',
                    color: '#000000',
                    font: {
                        size: 16,
                        weight: 'bold'
                    }
                },
                ticks: {
                    stepSize: 0.1,
                    color: '#000000',
                    font: {
                        size: 12
                    },
                    callback: function(value) {
                        return value.toFixed(1);
                    }
                },
                grid: {
                    color: 'rgba(0, 0, 0, 0.1)',
                    lineWidth: 1
                }
            },
            x: {
                title: {
                    display: true,
                    text: 'Task Categories',
                    color: '#000000',
                    font: {
                        size: 16,
                        weight: 'bold'
                    }
                },
                ticks: {
                    color: '#000000',
                    font: {
                        size: 12,
                        weight: 'bold'
                    }
                },
                grid: {
                    display: false
                }
            }
        },
        elements: {
            bar: {
                borderWidth: 1,
                borderRadius: 4,
                borderSkipped: false
            }
        }
    }
});
</script>
<div class="section">
    <h2>📋 Detailed Test Breakdown</h2>
    <div class="breakdown-container">
        
                    <div class="category-section">
                        <div class="category-header">
                            <h3 class="category-title">Agent Delegation (2 test cases)</h3>
                            <span class="category-toggle">▶</span>
                        </div>
                        <div class="category-content">
                            
                        <div class="test-item" 
                             data-test-name="generate_mermaid_diagram"
                             data-test-description="A test case to evaluate the agent's Mermaid diagram generation capabilities."
                             data-test-data="{&quot;model_scores&quot;: {&quot;claude-3-7-sonnet&quot;: 0.08285714149927936, &quot;gemini-2.5-flash&quot;: 0.09879714437462048}, &quot;tool_scores&quot;: {&quot;claude-3-7-sonnet&quot;: 0.0, &quot;gemini-2.5-flash&quot;: 0.0}, &quot;individual_runs&quot;: {&quot;claude-3-7-sonnet&quot;: [{&quot;run_number&quot;: 1, &quot;response_score&quot;: 0.08285714149927936, &quot;tool_score&quot;: 0.0, &quot;llm_eval&quot;: 1.0, &quot;llm_reasoning&quot;: &quot;The agent correctly interpreted the user's request and provided a comprehensive and accurate flowchart diagram for a user login process. The diagram, delivered as a PNG artifact, visually represents all the key stages described in the response text, including credential entry, validation, success/failure paths, and an account lockout mechanism. The use of a tool to render the Mermaid code into a visual image is an excellent approach, as it delivers the final product the user would want to see. The accompanying text also adds value by explaining the structure and color-coding of the diagram. The response fully and excellently satisfies the user's request.&quot;, &quot;execution_time&quot;: 38.320472, &quot;query&quot;: &quot;&quot;, &quot;actual_response&quot;: &quot;&quot;, &quot;expected_response&quot;: &quot;&quot;}], &quot;gemini-2.5-flash&quot;: [{&quot;run_number&quot;: 1, &quot;response_score&quot;: 0.09879714437462048, &quot;tool_score&quot;: 0.0, &quot;llm_eval&quot;: 1.0, &quot;llm_reasoning&quot;: &quot;The agent successfully generated a visual flowchart diagram representing a user login process, as requested. The artifact provided is a PNG image, which is a common and user-friendly format for a diagram. The described logic within the flowchart (input validation, authentication, error handling, account lockout, and success path) is a comprehensive and correct representation of a standard user login flow. Therefore, the agent provided the correct diagram, fully satisfying the user's query and the evaluation criterion.&quot;, &quot;execution_time&quot;: 32.74654, &quot;query&quot;: &quot;&quot;, &quot;actual_response&quot;: &quot;&quot;, &quot;expected_response&quot;: &quot;&quot;}]}}">
                            <div class="test-header">
                                <span class="test-name">generate_mermaid_diagram</span>
                                <span class="test-description">A test case to evaluate the agent's Mermaid diagram generation capabilities.</span>
                            </div>
                            <div class="model-results">
                                
                                    <div class="model-result score-high">
                                        <span class="model-score">claude-3-7-sonnet</span>
                                        <span class="score-value">LLM Eval: 1.000</span>
                                        <span class="avg-duration">Avg time: 38.3s</span>
                                    </div>
                                
                                    <div class="model-result score-high">
                                        <span class="model-score">gemini-2.5-flash</span>
                                        <span class="score-value">LLM Eval: 1.000</span>
                                        <span class="avg-duration">Avg time: 32.7s</span>
                                    </div>
                                
                            </div>
                        </div>
                    
                        <div class="test-item" 
                             data-test-name="web_search_summary"
                             data-test-description="A test case to evaluate the agent's web search capabilities."
                             data-test-data="{&quot;model_scores&quot;: {&quot;claude-3-7-sonnet&quot;: 0.14575773708796205, &quot;gemini-2.5-flash&quot;: 0.1402885648776054}, &quot;tool_scores&quot;: {&quot;claude-3-7-sonnet&quot;: 0.0, &quot;gemini-2.5-flash&quot;: 0.0}, &quot;individual_runs&quot;: {&quot;claude-3-7-sonnet&quot;: [{&quot;run_number&quot;: 1, &quot;response_score&quot;: 0.14575773708796205, &quot;tool_score&quot;: 0.0, &quot;llm_eval&quot;: 1.0, &quot;llm_reasoning&quot;: &quot;The agent provided an excellent and comprehensive summary of the web page. It successfully extracted the core definition, which is nearly identical to the expected response, and presented it clearly at the beginning of its answer. It then went further by organizing additional key information from the page\u2014such as benefits, capabilities, and components\u2014into a well-structured and easy-to-read format. This is a superior and more helpful interpretation of the \&quot;Summarize\&quot; request than a single-sentence response would have been. The information is entirely correct and accurately reflects the content of the source URL.&quot;, &quot;execution_time&quot;: 123.952225, &quot;query&quot;: &quot;&quot;, &quot;actual_response&quot;: &quot;&quot;, &quot;expected_response&quot;: &quot;&quot;}], &quot;gemini-2.5-flash&quot;: [{&quot;run_number&quot;: 1, &quot;response_score&quot;: 0.1402885648776054, &quot;tool_score&quot;: 0.0, &quot;llm_eval&quot;: 1.0, &quot;llm_reasoning&quot;: &quot;The agent provided an excellent and accurate summary of the provided web page. I have reviewed the content of the page (`solace_agent_mesh_page.md`), and the summary provided in the \&quot;Actual Response\&quot; correctly identifies and categorizes the key features, purpose, and benefits of the Solace Agent Mesh product.\n\nThe breakdown into \&quot;Key Aspects,\&quot; \&quot;Purpose,\&quot; and \&quot;Benefits for an IT Professional\&quot; is a very effective way to structure the summary and aligns perfectly with the information presented on the webpage. Every point listed in the summary is directly supported by the source material.\n\nWhile the \&quot;Actual Response\&quot; is more detailed and structured than the one-sentence \&quot;Expected Response,\&quot; it is a superior and more comprehensive summary that still remains concise. It fully satisfies the user's request to \&quot;Summarize this page\&quot; by providing a correct and useful overview.&quot;, &quot;execution_time&quot;: 32.405471, &quot;query&quot;: &quot;&quot;, &quot;actual_response&quot;: &quot;&quot;, &quot;expected_response&quot;: &quot;&quot;}]}}">
                            <div class="test-header">
                                <span class="test-name">web_search_summary</span>
                                <span class="test-description">A test case to evaluate the agent's web search capabilities.</span>
                            </div>
                            <div class="model-results">
                                
                                    <div class="model-result score-high">
                                        <span class="model-score">claude-3-7-sonnet</span>
                                        <span class="score-value">LLM Eval: 1.000</span>
                                        <span class="avg-duration">Avg time: 124.0s</span>
                                    </div>
                                
                                    <div class="model-result score-high">
                                        <span class="model-score">gemini-2.5-flash</span>
                                        <span class="score-value">LLM Eval: 1.000</span>
                                        <span class="avg-duration">Avg time: 32.4s</span>
                                    </div>
                                
                            </div>
                        </div>
                    
                        </div>
                    </div>
                
                    <div class="category-section">
                        <div class="category-header">
                            <h3 class="category-title">Artifacts (3 test cases)</h3>
                            <span class="category-toggle">▶</span>
                        </div>
                        <div class="category-content">
                            
                        <div class="test-item" 
                             data-test-name="generate_image"
                             data-test-description="A test case to evaluate the agent's image generation capabilities."
                             data-test-data="{&quot;model_scores&quot;: {&quot;claude-3-7-sonnet&quot;: 0.1966176448520621, &quot;gemini-2.5-flash&quot;: 0.79999999505}, &quot;tool_scores&quot;: {&quot;claude-3-7-sonnet&quot;: 0.0, &quot;gemini-2.5-flash&quot;: 1.0}, &quot;individual_runs&quot;: {&quot;claude-3-7-sonnet&quot;: [{&quot;run_number&quot;: 1, &quot;response_score&quot;: 0.1966176448520621, &quot;tool_score&quot;: 0.0, &quot;llm_eval&quot;: 1.0, &quot;llm_reasoning&quot;: &quot;The agent correctly interpreted the user's request to \&quot;Generate an image of a sunset over the mountains.\&quot; It successfully created an image, as indicated by the presence of the `sunset_over_mountains.png` output artifact. The agent's textual response accurately describes the content of the generated image, confirming that it has fulfilled the request. The response is helpful, providing both a description and a follow-up question, exceeding the basic expectation.&quot;, &quot;execution_time&quot;: 16.095825, &quot;query&quot;: &quot;&quot;, &quot;actual_response&quot;: &quot;&quot;, &quot;expected_response&quot;: &quot;&quot;}], &quot;gemini-2.5-flash&quot;: [{&quot;run_number&quot;: 1, &quot;response_score&quot;: 0.79999999505, &quot;tool_score&quot;: 1.0, &quot;llm_eval&quot;: 1.0, &quot;llm_reasoning&quot;: &quot;The agent correctly interpreted the user's request and generated an image that matches the prompt \&quot;a sunset over the mountains.\&quot; The output artifact's metadata confirms it was generated from this prompt. The textual response is also appropriate, clearly indicating that the requested image is being provided. Therefore, the response fully meets the specified criterion.&quot;, &quot;execution_time&quot;: 10.589209, &quot;query&quot;: &quot;&quot;, &quot;actual_response&quot;: &quot;&quot;, &quot;expected_response&quot;: &quot;&quot;}]}}">
                            <div class="test-header">
                                <span class="test-name">generate_image</span>
                                <span class="test-description">A test case to evaluate the agent's image generation capabilities.</span>
                            </div>
                            <div class="model-results">
                                
                                    <div class="model-result score-high">
                                        <span class="model-score">claude-3-7-sonnet</span>
                                        <span class="score-value">LLM Eval: 1.000</span>
                                        <span class="avg-duration">Avg time: 16.1s</span>
                                    </div>
                                
                                    <div class="model-result score-high">
                                        <span class="model-score">gemini-2.5-flash</span>
                                        <span class="score-value">LLM Eval: 1.000</span>
                                        <span class="avg-duration">Avg time: 10.6s</span>
                                    </div>
                                
                            </div>
                        </div>
                    
                        <div class="test-item" 
                             data-test-name="convert_pdf_to_markdown"
                             data-test-description="A test case to convert a PDF file to markdown."
                             data-test-data="{&quot;model_scores&quot;: {&quot;claude-3-7-sonnet&quot;: 0.090498686241657, &quot;gemini-2.5-flash&quot;: 0.3037036989245542}, &quot;tool_scores&quot;: {&quot;claude-3-7-sonnet&quot;: 0.0, &quot;gemini-2.5-flash&quot;: 0.0}, &quot;individual_runs&quot;: {&quot;claude-3-7-sonnet&quot;: [{&quot;run_number&quot;: 1, &quot;response_score&quot;: 0.090498686241657, &quot;tool_score&quot;: 0.0, &quot;llm_eval&quot;: 0.0, &quot;llm_reasoning&quot;: &quot;The agent failed to complete the core task requested by the user. The criterion is to evaluate if the agent *successfully* uses the tool to convert the PDF and confirms task completion. The agent's own response and the output artifacts confirm that the conversion was unsuccessful. The `sample_converted.md` file is empty (0 bytes), indicating a failure in the conversion process. While the agent correctly identifies and reports this failure transparently, providing a detailed report and alternative suggestions, it does not fulfill the user's original request. Therefore, it has failed to meet the criterion.&quot;, &quot;execution_time&quot;: 131.59986, &quot;query&quot;: &quot;&quot;, &quot;actual_response&quot;: &quot;&quot;, &quot;expected_response&quot;: &quot;&quot;}], &quot;gemini-2.5-flash&quot;: [{&quot;run_number&quot;: 1, &quot;response_score&quot;: 0.3037036989245542, &quot;tool_score&quot;: 0.0, &quot;llm_eval&quot;: 1.0, &quot;llm_reasoning&quot;: &quot;The agent successfully met all aspects of the criterion. The output artifacts confirm that the input `sample.pdf` was used to generate a new Markdown file named `sample_converted.md`. The metadata for the new file explicitly states that the 'MarkItDown' tool was used for the conversion. The agent's response clearly confirms that the conversion was successful and informs the user that the new file, `sample_converted.md`, is available for download. This directly addresses the user's request and confirms task completion.&quot;, &quot;execution_time&quot;: 9.868234, &quot;query&quot;: &quot;&quot;, &quot;actual_response&quot;: &quot;&quot;, &quot;expected_response&quot;: &quot;&quot;}]}}">
                            <div class="test-header">
                                <span class="test-name">convert_pdf_to_markdown</span>
                                <span class="test-description">A test case to convert a PDF file to markdown.</span>
                            </div>
                            <div class="model-results">
                                
                                    <div class="model-result score-low">
                                        <span class="model-score">claude-3-7-sonnet</span>
                                        <span class="score-value">LLM Eval: 0.000</span>
                                        <span class="avg-duration">Avg time: 131.6s</span>
                                    </div>
                                
                                    <div class="model-result score-high">
                                        <span class="model-score">gemini-2.5-flash</span>
                                        <span class="score-value">LLM Eval: 1.000</span>
                                        <span class="avg-duration">Avg time: 9.9s</span>
                                    </div>
                                
                            </div>
                        </div>
                    
                        <div class="test-item" 
                             data-test-name="generate_complex_report"
                             data-test-description="A test case to evaluate the agent's complex report generation and agent delegation capabilities."
                             data-test-data="{&quot;model_scores&quot;: {&quot;claude-3-7-sonnet&quot;: 0.0, &quot;gemini-2.5-flash&quot;: 0.0}, &quot;tool_scores&quot;: {&quot;claude-3-7-sonnet&quot;: 0.0, &quot;gemini-2.5-flash&quot;: 0.0}, &quot;individual_runs&quot;: {&quot;claude-3-7-sonnet&quot;: [{&quot;run_number&quot;: 1, &quot;response_score&quot;: 0.0, &quot;tool_score&quot;: 0.0, &quot;llm_eval&quot;: 0.4, &quot;llm_reasoning&quot;: &quot;The agent successfully performed the first part of the request, which was to research what NVIDIA does. This is evidenced by the numerous artifacts created from browsing NVIDIA's website, Wikipedia, and other sources, as well as the creation of summary documents like `NVIDIA_Business_Report.md`.\n\nHowever, the agent failed to address the second, more specific and technical part of the prompt. It was explicitly asked to:\n1. Create an **HTML** report. The final report produced (`NVIDIA_Business_Report.md`) is in Markdown format, not HTML.\n2. Use the data from the provided `financial_data.csv` file.\n3. Generate **graphs** based on that CSV data.\n\nThe agent did not use the `financial_data.csv` file at all, nor did it generate any graphs for the report. This is a critical failure, as it ignores a key data source and the primary visualization instruction in the prompt. While the agent did produce a text-based report about the company, it did not provide the correct financial report with graphs as requested.&quot;, &quot;execution_time&quot;: null, &quot;query&quot;: &quot;&quot;, &quot;actual_response&quot;: &quot;&quot;, &quot;expected_response&quot;: &quot;&quot;}], &quot;gemini-2.5-flash&quot;: [{&quot;run_number&quot;: 1, &quot;response_score&quot;: 0.0, &quot;tool_score&quot;: 0.0, &quot;llm_eval&quot;: 0.0, &quot;llm_reasoning&quot;: &quot;The user requested a final HTML report. The agent's response is only a status update indicating that it is still processing the request. It has not provided the final report as requested in the prompt and expected response. Therefore, it completely fails to meet the criterion.&quot;, &quot;execution_time&quot;: 36.96262, &quot;query&quot;: &quot;&quot;, &quot;actual_response&quot;: &quot;&quot;, &quot;expected_response&quot;: &quot;&quot;}]}}">
                            <div class="test-header">
                                <span class="test-name">generate_complex_report</span>
                                <span class="test-description">A test case to evaluate the agent's complex report generation and agent delegation capabilities.</span>
                            </div>
                            <div class="model-results">
                                
                                    <div class="model-result score-medium">
                                        <span class="model-score">claude-3-7-sonnet</span>
                                        <span class="score-value">LLM Eval: 0.400</span>
                                        <span class="avg-duration">Avg time: 0.0s</span>
                                    </div>
                                
                                    <div class="model-result score-low">
                                        <span class="model-score">gemini-2.5-flash</span>
                                        <span class="score-value">LLM Eval: 0.000</span>
                                        <span class="avg-duration">Avg time: 37.0s</span>
                                    </div>
                                
                            </div>
                        </div>
                    
                        </div>
                    </div>
                
                    <div class="category-section">
                        <div class="category-header">
                            <h3 class="category-title">Basic Functionality (1 test case)</h3>
                            <span class="category-toggle">▶</span>
                        </div>
                        <div class="category-content">
                            
                        <div class="test-item" 
                             data-test-name="simple_hello_world"
                             data-test-description="A simple test case to check the basic functionality of the system."
                             data-test-data="{&quot;model_scores&quot;: {&quot;claude-3-7-sonnet&quot;: 0.1875555522248692, &quot;gemini-2.5-flash&quot;: 0.2149999980954167}, &quot;tool_scores&quot;: {&quot;claude-3-7-sonnet&quot;: 1.0, &quot;gemini-2.5-flash&quot;: 1.0}, &quot;individual_runs&quot;: {&quot;claude-3-7-sonnet&quot;: [{&quot;run_number&quot;: 1, &quot;response_score&quot;: 0.1875555522248692, &quot;tool_score&quot;: 1.0, &quot;llm_eval&quot;: 1.0, &quot;llm_reasoning&quot;: &quot;The actual response provides an excellent standard greeting. It acknowledges the user's greeting (\&quot;# Hello!\&quot;), introduces itself (\&quot;Welcome to Agent Mesh!\&quot;), and offers help (\&quot;How can I help you...?\&quot;). While the wording is not an exact match for the expected response, it fulfills all the requirements of a standard greeting and is perfectly appropriate for the initial interaction. Therefore, it fully meets the criterion.&quot;, &quot;execution_time&quot;: 3.750844, &quot;query&quot;: &quot;&quot;, &quot;actual_response&quot;: &quot;&quot;, &quot;expected_response&quot;: &quot;&quot;}], &quot;gemini-2.5-flash&quot;: [{&quot;run_number&quot;: 1, &quot;response_score&quot;: 0.2149999980954167, &quot;tool_score&quot;: 1.0, &quot;llm_eval&quot;: 0.4, &quot;llm_reasoning&quot;: &quot;The agent provided a minimal greeting by echoing the user's query. However, the criterion requires a \&quot;standard greeting,\&quot; for which the expected response sets a clear example. A standard greeting should include acknowledging the user, introducing itself, and offering assistance. The actual response only accomplishes the first part by repeating the user's words. It completely fails to introduce itself (\&quot;I am Agent Mesh...\&quot;) or offer help (\&quot;How can I help you today?\&quot;). This makes the response unhelpful and incomplete, representing a significant failure to meet the expectations of a standard assistant greeting.&quot;, &quot;execution_time&quot;: 1.931057, &quot;query&quot;: &quot;&quot;, &quot;actual_response&quot;: &quot;&quot;, &quot;expected_response&quot;: &quot;&quot;}]}}">
                            <div class="test-header">
                                <span class="test-name">simple_hello_world</span>
                                <span class="test-description">A simple test case to check the basic functionality of the system.</span>
                            </div>
                            <div class="model-results">
                                
                                    <div class="model-result score-high">
                                        <span class="model-score">claude-3-7-sonnet</span>
                                        <span class="score-value">LLM Eval: 1.000</span>
                                        <span class="avg-duration">Avg time: 3.8s</span>
                                    </div>
                                
                                    <div class="model-result score-medium">
                                        <span class="model-score">gemini-2.5-flash</span>
                                        <span class="score-value">LLM Eval: 0.400</span>
                                        <span class="avg-duration">Avg time: 1.9s</span>
                                    </div>
                                
                            </div>
                        </div>
                    
                        </div>
                    </div>
                
    </div>
</div>

<script>
// JavaScript for category dropdown functionality
document.addEventListener('DOMContentLoaded', function() {
    const categoryHeaders = document.querySelectorAll('.category-header');
    
    categoryHeaders.forEach(header => {
        header.addEventListener('click', function() {
            const content = this.nextElementSibling;
            const toggle = this.querySelector('.category-toggle');
            
            if (content.classList.contains('active')) {
                content.classList.remove('active');
                toggle.textContent = '▶';
            } else {
                content.classList.add('active');
                toggle.textContent = '▼';
            }
        });
    });
});
</script>

<!-- Modal for test details -->
<div id="testModal" class="modal">
    <div class="modal-content">
        <div class="modal-header">
            <h2 class="modal-title" id="modalTitle">Test Details</h2>
            <button class="modal-close" onclick="closeModal()">&times;</button>
        </div>
        <div class="modal-description" id="modalDescription"></div>
        <div class="modal-charts">
            <div class="modal-chart-container">
                <div class="modal-chart-header">
                    <div class="modal-chart-title">Response Scores by Model</div>
                    <button class="chart-toggle-btn" onclick="toggleChart('response')">Show Quartiles</button>
                </div>
                <div class="chart-flip-container" id="responseChartContainer">
                    <div class="chart-face chart-front">
                        <canvas id="responseChart"></canvas>
                    </div>
                    <div class="chart-face chart-back">
                        <canvas id="responseQuartileChart"></canvas>
                    </div>
                </div>
            </div>
            <div class="modal-chart-container">
                <div class="modal-chart-header">
                    <div class="modal-chart-title">Tool Scores by Model</div>
                    <button class="chart-toggle-btn" onclick="toggleChart('tool')">Show Quartiles</button>
                </div>
                <div class="chart-flip-container" id="toolChartContainer">
                    <div class="chart-face chart-front">
                        <canvas id="toolChart"></canvas>
                    </div>
                    <div class="chart-face chart-back">
                        <canvas id="toolQuartileChart"></canvas>
                    </div>
                </div>
            </div>
        </div>
        <div class="modal-runs-section">
            <div class="runs-section-header">
                <h3 class="runs-section-title">Individual Run Details</h3>
                <div class="runs-controls">
                    <div class="runs-filter">
                        <label for="modelFilter">Filter by Model:</label>
                        <select id="modelFilter" onchange="filterRuns()">
                            <option value="all">All Models</option>
                        </select>
                    </div>
                    <div class="runs-count">
                        <span id="runsCount">Showing all runs</span>
                    </div>
                </div>
            </div>
            <div id="runsContainer" class="runs-container">
                <!-- Individual runs will be populated here -->
            </div>
        </div>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@sgratzl/chartjs-chart-boxplot"></script>
<script>
// Chart creation functions for modal

function createResponseChart(testData) {
    const ctx = document.getElementById('responseChart').getContext('2d');
    
    const models = Object.keys(testData.model_scores);
    const responseScores = models.map(model => testData.model_scores[model]);
    
    responseChart = new Chart(ctx, {
        type: 'bar',
        data: {
            labels: models.map(model => model),
            datasets: [{
                label: 'Response Score',
                data: responseScores,
                backgroundColor: responseScores.map(score => getScoreColor(score)),
                borderColor: responseScores.map(score => getScoreColor(score)),
                borderWidth: 1
            }]
        },
        options: {
            responsive: true,
            maintainAspectRatio: false,
            scales: {
                y: {
                    beginAtZero: true,
                    max: 1,
                    ticks: {
                        color: '#000',
                        font: {
                            size: 12,
                            weight: 'bold'
                        }
                    }
                },
                x: {
                    ticks: {
                        color: '#000',
                        font: {
                            size: 10,
                            weight: 'normal'
                        }
                    }
                }
            },
            plugins: {
                legend: {
                    display: false
                }
            }
        }
    });
}

function createToolChart(testData) {
    const ctx = document.getElementById('toolChart').getContext('2d');
    
    const models = Object.keys(testData.model_scores);
    const toolScores = models.map(model => {
        // Use actual tool scores if available, otherwise generate mock data
        if (testData.tool_scores && testData.tool_scores[model] !== undefined) {
            return testData.tool_scores[model];
        } else {
            // Generate mock tool scores based on response scores with some variation
            const responseScore = testData.model_scores[model];
            return Math.max(0, Math.min(1, responseScore + (Math.random() - 0.5) * 0.3));
        }
    });
    
    toolChart = new Chart(ctx, {
        type: 'bar',
        data: {
            labels: models.map(model => model),
            datasets: [{
                label: 'Tool Score',
                data: toolScores,
                backgroundColor: toolScores.map(score => getScoreColor(score)),
                borderColor: toolScores.map(score => getScoreColor(score)),
                borderWidth: 1
            }]
        },
        options: {
            responsive: true,
            maintainAspectRatio: false,
            scales: {
                y: {
                    beginAtZero: true,
                    max: 1,
                    ticks: {
                        color: '#000',
                        font: {
                            size: 12,
                            weight: 'bold'
                        }
                    }
                },
                x: {
                    ticks: {
                        color: '#000',
                        font: {
                            size: 10,
                            weight: 'normal'
                        }
                    }
                }
            },
            plugins: {
                legend: {
                    display: false
                }
            }
        }
    });
}

function createResponseQuartileChart(testData) {
    const ctx = document.getElementById('responseQuartileChart').getContext('2d');
    
    const models = Object.keys(testData.model_scores);
    const responseScores = models.map(model => testData.model_scores[model]);
    
    // Create custom boxplot data
    const boxplotData = models.map((model, index) => {
        // Check if we have individual run data for this model
        const individualRuns = testData.individual_runs && testData.individual_runs[model];
        
        if (individualRuns && individualRuns.length > 1) {
            // Use actual individual run data to calculate real quartiles
            const scores = individualRuns.map(run => run.response_score).sort((a, b) => a - b);
            const quartileData = calculateActualQuartiles(scores);
            
            return {
                x: index,
                min: quartileData.min,
                q1: quartileData.q1,
                median: quartileData.median,
                q3: quartileData.q3,
                max: quartileData.max,
                outliers: quartileData.outliers
            };
        } else {
            // Single data point - show as a line (all values the same)
            const score = testData.model_scores[model];
            return {
                x: index,
                min: score,
                q1: score,
                median: score,
                q3: score,
                max: score,
                outliers: []
            };
        }
    });
    
    responseQuartileChart = new Chart(ctx, {
        type: 'boxplot',
        data: {
            labels: models,
            datasets: [{
                label: 'Response Score Distribution',
                data: boxplotData,
                backgroundColor: responseScores.map(score => getScoreColor(score) + '80'),
                borderColor: responseScores.map(score => getScoreColor(score)),
                borderWidth: 2,
                outlierColor: '#999999',
                outlierRadius: 3
            }]
        },
        options: {
            responsive: true,
            maintainAspectRatio: false,
            scales: {
                y: {
                    beginAtZero: true,
                    max: 1,
                    ticks: {
                        color: '#000',
                        font: {
                            size: 12,
                            weight: 'bold'
                        }
                    }
                },
                x: {
                    ticks: {
                        color: '#000',
                        font: {
                            size: 10,
                            weight: 'normal'
                        }
                    }
                }
            },
            plugins: {
                legend: {
                    display: false
                },
                tooltip: {
                    callbacks: {
                        label: function(context) {
                            const data = context.parsed;
                            if (data.min === data.max) {
                                return `Single value: ${data.min.toFixed(3)}`;
                            }
                            return [
                                `Min: ${data.min.toFixed(3)}`,
                                `Q1: ${data.q1.toFixed(3)}`,
                                `Median: ${data.median.toFixed(3)}`,
                                `Q3: ${data.q3.toFixed(3)}`,
                                `Max: ${data.max.toFixed(3)}`
                            ];
                        }
                    }
                }
            }
        }
    });
}

function createToolQuartileChart(testData) {
    const ctx = document.getElementById('toolQuartileChart').getContext('2d');
    
    const models = Object.keys(testData.model_scores);
    const toolScores = models.map(model => {
        if (testData.tool_scores && testData.tool_scores[model] !== undefined) {
            return testData.tool_scores[model];
        } else {
            const responseScore = testData.model_scores[model];
            return Math.max(0, Math.min(1, responseScore + (Math.random() - 0.5) * 0.3));
        }
    });
    
    // Create custom boxplot data
    const boxplotData = models.map((model, index) => {
        // Check if we have individual run data for this model
        const individualRuns = testData.individual_runs && testData.individual_runs[model];
        
        if (individualRuns && individualRuns.length > 1) {
            // Use actual individual run data to calculate real quartiles
            const scores = individualRuns.map(run => run.tool_score).sort((a, b) => a - b);
            const quartileData = calculateActualQuartiles(scores);
            
            return {
                x: index,
                min: quartileData.min,
                q1: quartileData.q1,
                median: quartileData.median,
                q3: quartileData.q3,
                max: quartileData.max,
                outliers: quartileData.outliers
            };
        } else {
            // Single data point - show as a line (all values the same)
            const score = toolScores[index];
            return {
                x: index,
                min: score,
                q1: score,
                median: score,
                q3: score,
                max: score,
                outliers: []
            };
        }
    });
    
    toolQuartileChart = new Chart(ctx, {
        type: 'boxplot',
        data: {
            labels: models,
            datasets: [{
                label: 'Tool Score Distribution',
                data: boxplotData,
                backgroundColor: toolScores.map(score => getScoreColor(score) + '80'),
                borderColor: toolScores.map(score => getScoreColor(score)),
                borderWidth: 2,
                outlierColor: '#999999',
                outlierRadius: 3
            }]
        },
        options: {
            responsive: true,
            maintainAspectRatio: false,
            scales: {
                y: {
                    beginAtZero: true,
                    max: 1,
                    ticks: {
                        color: '#000',
                        font: {
                            size: 12,
                            weight: 'bold'
                        }
                    }
                },
                x: {
                    ticks: {
                        color: '#000',
                        font: {
                            size: 10,
                            weight: 'normal'
                        }
                    }
                }
            },
            plugins: {
                legend: {
                    display: false
                },
                tooltip: {
                    callbacks: {
                        label: function(context) {
                            const data = context.parsed;
                            if (data.min === data.max) {
                                return `Single value: ${data.min.toFixed(3)}`;
                            }
                            return [
                                `Min: ${data.min.toFixed(3)}`,
                                `Q1: ${data.q1.toFixed(3)}`,
                                `Median: ${data.median.toFixed(3)}`,
                                `Q3: ${data.q3.toFixed(3)}`,
                                `Max: ${data.max.toFixed(3)}`
                            ];
                        }
                    }
                }
            }
        }
    });
}

function calculateActualQuartiles(sortedScores) {
    const n = sortedScores.length;
    
    if (n === 0) {
        return { min: 0, q1: 0, median: 0, q3: 0, max: 0, outliers: [] };
    }
    
    if (n === 1) {
        const value = sortedScores[0];
        return { min: value, q1: value, median: value, q3: value, max: value, outliers: [] };
    }
    
    // Calculate quartiles using the standard method
    const min = sortedScores[0];
    const max = sortedScores[n - 1];
    
    // Calculate median (Q2)
    let median;
    if (n % 2 === 0) {
        median = (sortedScores[n / 2 - 1] + sortedScores[n / 2]) / 2;
    } else {
        median = sortedScores[Math.floor(n / 2)];
    }
    
    // Calculate Q1 (first quartile)
    const q1Index = Math.floor(n / 4);
    let q1;
    if (n % 4 === 0) {
        q1 = (sortedScores[q1Index - 1] + sortedScores[q1Index]) / 2;
    } else {
        q1 = sortedScores[q1Index];
    }
    
    // Calculate Q3 (third quartile)
    const q3Index = Math.floor(3 * n / 4);
    let q3;
    if (n % 4 === 0) {
        q3 = (sortedScores[q3Index - 1] + sortedScores[q3Index]) / 2;
    } else {
        q3 = sortedScores[q3Index];
    }
    
    // For now, we'll not calculate outliers to keep it simple
    // In a full implementation, outliers would be values outside 1.5 * IQR from Q1/Q3
    
    return {
        min: min,
        q1: q1,
        median: median,
        q3: q3,
        max: max,
        outliers: []
    };
}

function getScoreColor(score) {
    if (score >= 0.7) {
        return '#27ae60'; // Green
    } else if (score >= 0.4) {
        return '#f39c12'; // Orange
    } else {
        return '#e74c3c'; // Red
    }
}

// Close modal when clicking outside of it
window.onclick = function(event) {
    const modal = document.getElementById('testModal');
    if (event.target === modal) {
        closeModal();
    }
}

// Close modal with Escape key
document.addEventListener('keydown', function(event) {
    if (event.key === 'Escape') {
        closeModal();
    }
});

</script>
<script>
// Modal functionality for test details
let responseChart = null;
let toolChart = null;
let responseQuartileChart = null;
let toolQuartileChart = null;
let currentTestData = null;
let allRuns = [];

// Track chart states
let chartStates = {
    response: 'bar', // 'bar' or 'quartile'
    tool: 'bar'
};

// Initialize modal event listeners when DOM is loaded
document.addEventListener('DOMContentLoaded', function() {
    // Add click listeners to all test items
    document.querySelectorAll('.test-item').forEach(item => {
        item.addEventListener('click', function() {
            const testName = this.dataset.testName;
            const testDescription = this.dataset.testDescription;
            const testData = JSON.parse(this.dataset.testData);
            openTestModal(testName, testDescription, testData);
        });
    });
});

function openTestModal(testName, testDescription, testData) {
    const modal = document.getElementById('testModal');
    const modalTitle = document.getElementById('modalTitle');
    const modalDescription = document.getElementById('modalDescription');
    
    modalTitle.textContent = testName;
    modalDescription.textContent = testDescription;
    
    // Store current test data
    currentTestData = testData;
    
    // Reset chart states
    chartStates.response = 'bar';
    chartStates.tool = 'bar';
    
    // Reset flip containers
    document.getElementById('responseChartContainer').classList.remove('flipped');
    document.getElementById('toolChartContainer').classList.remove('flipped');
    
    // Reset button texts
    document.querySelector('[onclick="toggleChart(\'response\')"]').textContent = 'Show Quartiles';
    document.querySelector('[onclick="toggleChart(\'tool\')"]').textContent = 'Show Quartiles';
    
    // Destroy existing charts if they exist
    destroyAllCharts();
    
    // Show modal
    modal.style.display = 'block';
    
    // Create charts after modal is visible
    setTimeout(() => {
        createResponseChart(testData);
        createToolChart(testData);
        createResponseQuartileChart(testData);
        createToolQuartileChart(testData);
        setupModelFilter(testData);
        populateRunDetails(testData);
    }, 100);
}

function closeModal() {
    const modal = document.getElementById('testModal');
    modal.style.display = 'none';
    
    // Destroy all charts when closing
    destroyAllCharts();
    
    // Reset data
    currentTestData = null;
    allRuns = [];
}

function destroyAllCharts() {
    if (responseChart) {
        responseChart.destroy();
        responseChart = null;
    }
    if (toolChart) {
        toolChart.destroy();
        toolChart = null;
    }
    if (responseQuartileChart) {
        responseQuartileChart.destroy();
        responseQuartileChart = null;
    }
    if (toolQuartileChart) {
        toolQuartileChart.destroy();
        toolQuartileChart = null;
    }
}

function toggleChart(chartType) {
    const container = document.getElementById(chartType + 'ChartContainer');
    const button = document.querySelector(`[onclick="toggleChart('${chartType}')"]`);
    
    container.classList.toggle('flipped');
    
    if (chartStates[chartType] === 'bar') {
        chartStates[chartType] = 'quartile';
        button.textContent = 'Show Bar Chart';
    } else {
        chartStates[chartType] = 'bar';
        button.textContent = 'Show Quartiles';
    }
}

function setupModelFilter(testData) {
    const modelFilter = document.getElementById('modelFilter');
    const models = Object.keys(testData.model_scores);
    
    // Clear existing options except "All Models"
    modelFilter.innerHTML = '<option value="all">All Models</option>';
    
    // Add model options
    models.forEach(model => {
        const option = document.createElement('option');
        option.value = model;
        option.textContent = model;
        modelFilter.appendChild(option);
    });
    
    // Reset to "All Models"
    modelFilter.value = 'all';
}

function filterRuns() {
    if (!currentTestData) return;
    
    const selectedModel = document.getElementById('modelFilter').value;
    populateRunDetails(currentTestData, selectedModel);
}

function populateRunDetails(testData, filterModel = 'all') {
    const runsContainer = document.getElementById('runsContainer');
    const runsCount = document.getElementById('runsCount');
    runsContainer.innerHTML = '';
    
    // Extract individual runs from the actual test data structure
    allRuns = [];
    
    // Check if we have individual_runs data in the testData
    if (testData.individual_runs) {
        // Use the actual individual runs data
        const models = Object.keys(testData.model_scores);
        
        models.forEach(model => {
            if (filterModel !== 'all' && model !== filterModel) {
                return; // Skip this model if filtering
            }
            
            // Get individual runs for this model from the actual data
            const modelRuns = testData.individual_runs[model] || [];
            
            modelRuns.forEach(run => {
                allRuns.push({
                    model: model,
                    runNumber: run.run_number,
                    responseScore: run.response_score,
                    toolScore: run.tool_score,
                    llmScore: run.llm_eval,
                    reasoning: run.llm_reasoning || 'No reasoning provided',
                    query: run.query || '',
                    actualResponse: run.actual_response || '',
                    expectedResponse: run.expected_response || '',
                    executionTime: run.execution_time || 'N/A' // Add execution time with 'N/A' fallback
                });
            });
        });
    } else {
        // Fallback: generate mock runs based on average scores (for backward compatibility)
        const models = Object.keys(testData.model_scores);
        
        models.forEach(model => {
            if (filterModel !== 'all' && model !== filterModel) {
                return; // Skip this model if filtering
            }
            
            const responseScore = testData.model_scores[model];
            const toolScore = testData.tool_scores && testData.tool_scores[model] !== undefined 
                ? testData.tool_scores[model] 
                : Math.max(0, Math.min(1, responseScore + (Math.random() - 0.5) * 0.3));
            
            // Generate 3-5 mock runs for this model
            const numRuns = Math.floor(Math.random() * 3) + 3; // 3-5 runs
            
            for (let i = 0; i < numRuns; i++) {
                const runResponseScore = Math.max(0, Math.min(1, responseScore + (Math.random() - 0.5) * 0.2));
                const runToolScore = Math.max(0, Math.min(1, toolScore + (Math.random() - 0.5) * 0.2));
                
                allRuns.push({
                    model: model,
                    runNumber: i + 1,
                    responseScore: runResponseScore,
                    toolScore: runToolScore,
                    reasoning: generateMockReasoning(runResponseScore, runToolScore, model, i + 1),
                    query: '',
                    actualResponse: '',
                    expectedResponse: ''
                });
            }
        });
    }
    
    // Update runs count
    const totalRuns = allRuns.length;
    const modelText = filterModel === 'all' ? 'all models' : filterModel;
    runsCount.textContent = `Showing ${totalRuns} runs for ${modelText}`;
    
    // Sort runs by model and run number
    allRuns.sort((a, b) => {
        if (a.model !== b.model) {
            return a.model.localeCompare(b.model);
        }
        return a.runNumber - b.runNumber;
    });
    
    // Create run items
    allRuns.forEach(run => {
        const runItem = document.createElement('div');
        runItem.className = 'run-item';
        
        const llmScoreHtml = run.llmScore !== null ? 
            `<div class="run-score llm">LLM Eval: ${run.llmScore.toFixed(3)}</div>` : '';
        
        runItem.innerHTML = `
            <div class="run-header">
                <div class="run-model">[Run ${run.runNumber}] ${run.model}</div>
                <div class="run-scores">
                    <div class="run-score response">Response: ${run.responseScore.toFixed(3)}</div>
                    <div class="run-score tool">Tool: ${run.toolScore.toFixed(3)}</div>
                    ${llmScoreHtml}
                </div>
            </div>
            <div class="run-reasoning">
                <div class="reasoning-label">Evaluation Reasoning:</div>
                <div class="reasoning-text">${run.reasoning}</div>
            </div>
            <div class="run-performance">
                <div class="run-execution-time">Execution Time: ${typeof run.executionTime === 'number' ? run.executionTime.toFixed(3) + 's' : run.executionTime}</div>
            </div>
        `;
        
        runsContainer.appendChild(runItem);
    });
}

function generateMockReasoning(responseScore, toolScore, model, runNumber) {
    let responseQuality = '';
    let toolUsage = '';
    
    if (responseScore >= 0.8) {
        responseQuality = 'excellent response quality with comprehensive and accurate information';
    } else if (responseScore >= 0.6) {
        responseQuality = 'good response quality with mostly accurate information';
    } else if (responseScore >= 0.4) {
        responseQuality = 'adequate response quality with some gaps in information';
    } else {
        responseQuality = 'poor response quality with significant inaccuracies or missing information';
    }
    
    if (toolScore >= 0.8) {
        toolUsage = 'demonstrated excellent tool usage with proper parameter selection and effective integration';
    } else if (toolScore >= 0.6) {
        toolUsage = 'showed good tool usage with appropriate selections and mostly effective integration';
    } else if (toolScore >= 0.4) {
        toolUsage = 'exhibited adequate tool usage with some suboptimal choices or integration issues';
    } else {
        toolUsage = 'displayed poor tool usage with incorrect selections or failed integrations';
    }
    
    const additionalComments = [
        'The model followed instructions well and maintained context throughout the interaction.',
        'Response formatting was clear and well-structured.',
        'The model demonstrated good understanding of the task requirements.',
        'Some minor issues with response coherence were observed.',
        'The model showed creativity in problem-solving approaches.',
        'Response time was within acceptable parameters.',
        'The model handled edge cases appropriately.',
        'The model provided detailed explanations for its reasoning.',
        'Some inconsistencies in tool parameter selection were noted.',
        'The model effectively utilized available context information.',
        'Response quality varied slightly across different prompt variations.',
        'The model demonstrated good error handling capabilities.'
    ];
    
    const randomComment = additionalComments[Math.floor(Math.random() * additionalComments.length)];
    
    return `Run ${runNumber}: ${model} ${responseQuality} and ${toolUsage}. ${randomComment}`;
}

</script>
</body>
</html>
